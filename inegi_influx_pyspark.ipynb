{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisosmx/spark/blob/main/inegi_influx_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaTIOCkCHrnI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY2UBUP1HqwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b3e7f6-d650-4cdd-8edf-f1ec3b88dc3c"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar -xzf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!mv spark-3.1.2-bin-hadoop3.2.tgz /opt/spark-3.1.2\n",
        "!pip install -q findspark\n",
        "!pip install pyspark==3.1.2 \n",
        "!ln -s /opt/spark-3.1.2 /opt/spark\n",
        "!export SPARK_HOME=/opt/spark\n",
        "!export PATH=$SPARK_HOME/bin:$PATH"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=a7bce4ea14bc66f05f8e7cb8ae1c3a0dcb0a9ded9a429a58ea7f21cd295a5697\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/88/9e/58ef1f74892fef590330ca0830b5b6d995ba29b44f977b3926\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.2 "
      ],
      "metadata": {
        "id": "O1G5AE0JVE14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b6a38e-bbed-461f-8c10-20adbc9da542"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.1.2 in /usr/local/lib/python3.8/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.8/dist-packages (from pyspark==3.1.2) (0.10.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze"
      ],
      "metadata": {
        "id": "WoWcUVo-VTww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWFsts1yI2vx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5013f452-7abe-4b60-d3fa-1cbf6059e406"
      },
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.1.2-bin-hadoop3.2'\n",
        "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-shell'\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.7.2 pyspark-shell'\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "sc = pyspark.SparkContext(\"local[*]\")\n",
        "spark = SparkSession(sc)\n",
        "\n",
        "print('Modules imported and Spark loaded')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modules imported and Spark loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfD90BHevlbG"
      },
      "source": [
        "# Loading data into PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e1baC18ybZ4"
      },
      "source": [
        "Getting data from Github repo without clonning the project, just using [raw.githubusercontent.com](https://stackoverflow.com/questions/39065921/what-do-raw-githubusercontent-com-urls-represent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv0MNyJHJV02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7135e4-dd57-4678-a655-60025d0ad1f2"
      },
      "source": [
        "!wget --continue /content/afluenciastc_simple_01_2023.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/afluenciastc_simple_01_2023.csv: Scheme missing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wajfiPtGyuyu"
      },
      "source": [
        "Reading the file with a Spark dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eYhKMt9xQjV",
        "outputId": "db7331b1-58f4-4afb-aed2-3b6e0ff7538c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark_df = spark.read.csv('/content/afluenciastc_simple_01_2023.csv')\n",
        "spark_df.show(10)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-----+-------+-------------------+---------+\n",
            "|       _c0| _c1|  _c2|    _c3|                _c4|      _c5|\n",
            "+----------+----+-----+-------+-------------------+---------+\n",
            "|     fecha|anio|  mes|  linea|           estacion|afluencia|\n",
            "|2010-01-01|2010|Enero|Linea 1|           Zaragoza|    20227|\n",
            "|2010-01-01|2010|Enero|Linea 1| Isabel la Católica|     6487|\n",
            "|2010-01-01|2010|Enero|Linea 1|          Moctezuma|    10304|\n",
            "|2010-01-01|2010|Enero|Linea 1|        Pino Suárez|     8679|\n",
            "|2010-01-01|2010|Enero|Linea 1|       Gómez Farías|    19499|\n",
            "|2010-01-01|2010|Enero|Linea 6|Deptvo. 18 de Marzo|      621|\n",
            "|2010-01-01|2010|Enero|Linea 6|  La Villa-Basilica|    24792|\n",
            "|2010-01-01|2010|Enero|Linea 9|          Pantitlán|    27000|\n",
            "|2010-01-01|2010|Enero|Linea 8|             Aculco|     3652|\n",
            "+----------+----+-----+-------+-------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",True).csv('/content/afluenciastc_simple_01_2023.csv')\n",
        "df.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHRYvFH1TR3O",
        "outputId": "bae79c33-ac53-4ef7-db8a-e28f4a27d21c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-----+-------+-------------------+---------+\n",
            "|     fecha|anio|  mes|  linea|           estacion|afluencia|\n",
            "+----------+----+-----+-------+-------------------+---------+\n",
            "|2010-01-01|2010|Enero|Linea 1|           Zaragoza|    20227|\n",
            "|2010-01-01|2010|Enero|Linea 1| Isabel la Católica|     6487|\n",
            "|2010-01-01|2010|Enero|Linea 1|          Moctezuma|    10304|\n",
            "|2010-01-01|2010|Enero|Linea 1|        Pino Suárez|     8679|\n",
            "|2010-01-01|2010|Enero|Linea 1|       Gómez Farías|    19499|\n",
            "|2010-01-01|2010|Enero|Linea 6|Deptvo. 18 de Marzo|      621|\n",
            "|2010-01-01|2010|Enero|Linea 6|  La Villa-Basilica|    24792|\n",
            "|2010-01-01|2010|Enero|Linea 9|          Pantitlán|    27000|\n",
            "|2010-01-01|2010|Enero|Linea 8|             Aculco|     3652|\n",
            "|2010-01-01|2010|Enero|Linea 9|          Velódromo|     3239|\n",
            "|2010-01-01|2010|Enero|Linea 5|Autobuses del Norte|    16824|\n",
            "|2010-01-01|2010|Enero|Linea 5|          Misterios|     3513|\n",
            "|2010-01-01|2010|Enero|Linea 7|     Constituyentes|     1417|\n",
            "|2010-01-01|2010|Enero|Linea 7|          Refinería|     2325|\n",
            "|2010-01-01|2010|Enero|Linea 3|            Etiopía|     7078|\n",
            "|2010-01-01|2010|Enero|Linea 7|            Polanco|     6173|\n",
            "|2010-01-01|2010|Enero|Linea 4|    Canal del Norte|     2317|\n",
            "|2010-01-01|2010|Enero|Linea 4|          Bondojito|     2474|\n",
            "|2010-01-01|2010|Enero|Linea 4|        Santa Anita|     1042|\n",
            "|2010-01-01|2010|Enero|Linea 2|            Popotla|     2419|\n",
            "+----------+----+-----+-------+-------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.option(\"header\",True) \\\n",
        "          .csv(\"/content/afluenciastc_simple_01_2023.csv\") \\\n",
        "          .createOrReplaceTempView(\"influx_file\")"
      ],
      "metadata": {
        "id": "Sja5rkAiEzPr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM influx_file\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_WAPJqOFwvk",
        "outputId": "b11a9600-7bc4-4dd9-a60b-b6d4075a8d2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-----+-------+-------------------+---------+\n",
            "|     fecha|anio|  mes|  linea|           estacion|afluencia|\n",
            "+----------+----+-----+-------+-------------------+---------+\n",
            "|2010-01-01|2010|Enero|Linea 1|           Zaragoza|    20227|\n",
            "|2010-01-01|2010|Enero|Linea 1| Isabel la Católica|     6487|\n",
            "|2010-01-01|2010|Enero|Linea 1|          Moctezuma|    10304|\n",
            "|2010-01-01|2010|Enero|Linea 1|        Pino Suárez|     8679|\n",
            "|2010-01-01|2010|Enero|Linea 1|       Gómez Farías|    19499|\n",
            "|2010-01-01|2010|Enero|Linea 6|Deptvo. 18 de Marzo|      621|\n",
            "|2010-01-01|2010|Enero|Linea 6|  La Villa-Basilica|    24792|\n",
            "|2010-01-01|2010|Enero|Linea 9|          Pantitlán|    27000|\n",
            "|2010-01-01|2010|Enero|Linea 8|             Aculco|     3652|\n",
            "|2010-01-01|2010|Enero|Linea 9|          Velódromo|     3239|\n",
            "+----------+----+-----+-------+-------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = spark.sql(\"\"\"\n",
        "  SELECT \n",
        "    fecha AS date\n",
        "    , anio AS year\n",
        "    , mes AS month\n",
        "    , linea AS line\n",
        "    , estacion AS station\n",
        "    , afluencia AS influx\n",
        "  FROM influx_file\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "PRSgwh92GPfv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Replace months by numbers"
      ],
      "metadata": {
        "id": "xZLDJH7B5j5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.createOrReplaceTempView(\"df_1\")"
      ],
      "metadata": {
        "id": "t4xJjv_gRut5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT\n",
        "      CASE \n",
        "        WHEN month = 'Enero' THEN '01'\n",
        "        WHEN month = 'Febrero' THEN '02'\n",
        "        WHEN month = 'Marzo' THEN '03'\n",
        "        WHEN month = 'Abril' THEN '04'\n",
        "        WHEN month = 'Mayo' THEN '05'\n",
        "        WHEN month = 'Junio' THEN '06'\n",
        "        WHEN month = 'Julio' THEN '07'\n",
        "        WHEN month = 'Agosto' THEN '08'\n",
        "        WHEN month = 'Septiembre' THEN '09'\n",
        "        WHEN month = 'Octubre' THEN '10'\n",
        "        WHEN month = 'Noviembre' THEN '11'\n",
        "        WHEN month = 'Diciembre' THEN '12'\n",
        "        ELSE month\n",
        "      END AS Month\n",
        "  FROM df_1\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy_TMb6RZ5AL",
        "outputId": "24eb2a80-16ec-4581-f7de-1955259ec186"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|Month|\n",
            "+-----+\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "|   01|\n",
            "+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6XS5a_NVZvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Replace line by numbers"
      ],
      "metadata": {
        "id": "KALCF1aG_bBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sorting"
      ],
      "metadata": {
        "id": "79dhsQCF5mv4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bdimFKNGO0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}